# Place your best.pt model file here
#
# Copy from: C:\SNIX\LPT_INTERN\training\training_results_20260108_002532\train\weights\best.pt
#
# After the Docker image is built and running, you can also export
# the TensorRT engine inside the container:
#   sudo docker-compose run defect-detector python /app/export_tensorrt.py
#
# This will create best.engine in this same directory (3-5x faster inference)
